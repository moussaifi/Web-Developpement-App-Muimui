{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T07:16:47.552944Z",
     "start_time": "2019-03-27T07:16:47.550472Z"
    }
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T07:23:18.404701Z",
     "start_time": "2019-03-27T07:23:18.395529Z"
    }
   },
   "outputs": [],
   "source": [
    "def web_scrape(brand, url):\n",
    "    driver = webdriver.Chrome()\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    \n",
    "    driver.get(url)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            wait.until(\n",
    "                EC.visibility_of_element_located((\n",
    "                    By.XPATH, '//button[contains(@class, \"button js-load-more \")]')))\n",
    "            driver.find_element_by_xpath(\n",
    "                '//button[contains(@class, \"button js-load-more \")]').click()\n",
    "        except Exception:\n",
    "            break\n",
    "    \n",
    "    main_page = driver.page_source\n",
    "    main_soup = BeautifulSoup(main_page, \"lxml\")\n",
    "    \n",
    "    prod_pages = []\n",
    "    prod_names = []\n",
    "    prod_prices = []\n",
    "    prod_dp = []\n",
    "    prod_images = []\n",
    "    \n",
    "    for item in main_soup.find_all('a', {'class': 'item-link'}):\n",
    "        href = item.attrs['href']\n",
    "        item_link = 'https://www2.hm.com' + href\n",
    "        prod_pages.append(item_link)\n",
    "        \n",
    "        page = requests.get(item_link).content\n",
    "        soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "        name = soup.find('h1', \n",
    "                         {'class': 'primary product-item-headline'}).text.strip('\\r\\n\\t\\t\\t\\t\\t\\t\\t  ')\n",
    "        prod_names.append(name)\n",
    "\n",
    "        price = soup.find('span', \n",
    "                          {'class': 'price-value'}).text.strip('\\r\\n                $')\n",
    "        price = float(price)\n",
    "        prod_prices.append(price)\n",
    "\n",
    "        dp = soup.find('p', {'class': 'pdp-description-text'}).text\n",
    "        prod_dp.append(dp)\n",
    "\n",
    "        image = soup.find('div', \n",
    "                          {'class': 'product-detail-main-image-container'}).find('img').attrs['src']\n",
    "        url = 'http:' + image\n",
    "        prod_images.append(url)\n",
    "    \n",
    "    d = {'prod_page_link': prod_pages, \n",
    "         'image_link': prod_images,\n",
    "         'name': prod_names, \n",
    "         'price': prod_prices, \n",
    "         'description': prod_dp}\n",
    "    \n",
    "    df = pd.DataFrame(d)\n",
    "    df['brand'] = brand\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T07:23:29.958906Z",
     "start_time": "2019-03-27T07:23:19.436664Z"
    }
   },
   "outputs": [],
   "source": [
    "brand = 'H&M'\n",
    "url = 'https://www2.hm.com/en_us/women/products/view-all.html'\n",
    "df = web_scrape(brand, url)\n",
    "df.to_csv('HM.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
